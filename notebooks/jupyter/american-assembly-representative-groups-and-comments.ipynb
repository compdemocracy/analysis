{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pol-is/notebooks/blob/master/020-PCA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import altair as alt\n",
    "from textwrap import wrap\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up plots\n",
    "plt.figure(figsize=(500, 500))\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "sns.set_theme(font_scale=.7)\n",
    "sns.set_color_codes()\n",
    "\n",
    "%matplotlib inline\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw data && clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/bowling-green.american-assembly/participants-votes.csv',index_col='participant')\n",
    "df_comments = pd.read_csv('../../data/bowling-green.american-assembly/comments.csv',index_col='comment-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.index = df_comments.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fields = ['group-id', 'n-comments', 'n-votes', \n",
    "                   'n-agree', 'n-disagree']\n",
    "val_fields = [c for c in df.columns.values if c not in metadata_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove statements (columns) which were moderated out\n",
    "statements_all_in = sorted(list(df_comments.loc[df_comments[\"moderated\"] > 0].index.array), key = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for a row, count the number of finite values\n",
    "def count_finite(row):\n",
    "    finite = np.isfinite(row[val_fields]) # boolean array of whether each entry is finite\n",
    "    return sum(finite) # count number of True values in `finite`\n",
    "\n",
    "## REMOVE PARTICIPANTS WITH LESS THAN N VOTES check for each row if the number of finite values >= cutoff\n",
    "def select_rows(df, threshold=7):\n",
    "    \n",
    "    number_of_votes = df.apply(count_finite, axis=1)\n",
    "    valid = number_of_votes >= threshold\n",
    "    \n",
    "    return df[valid]\n",
    "    \n",
    "df = select_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = df[metadata_fields]\n",
    "vals = df[val_fields]\n",
    "# If the participant didn't see the statement, it's a null value, here we fill in the nulls with zeros\n",
    "vals = vals.fillna(0)  #<---in paper: column mean\n",
    "vals = vals.sort_values(\"participant\")\n",
    "vals_all_in = vals[statements_all_in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How sparse is the dataset? How much agree, how much disagree, how much pass? Zero is 'passed' or 'did not see the comment to vote on it'. 1 is agree, -1 is disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = vals.melt();\n",
    "all_votes = melted.count();\n",
    "by_type = melted[\"value\"].value_counts();\n",
    "total_possible_votes = all_votes[\"value\"];\n",
    "total_agrees = by_type[1.0];\n",
    "total_disagrees = by_type[-1.0];\n",
    "total_without_vote = by_type[0.0];\n",
    "\n",
    "print(\"Dimensions of matrix:\", df.shape)\n",
    "print(\"Dimensions of matrix:\", vals.shape)\n",
    "print(\"Total number of possible votes:\", total_possible_votes)\n",
    "print(\"Total number of agrees:\", total_agrees)\n",
    "print(\"Total number of disagrees:\", total_disagrees)\n",
    "print(\"Total without vote:\", total_without_vote)\n",
    "print(\"Percent sparse: \", total_without_vote / total_possible_votes,\"%\")\n",
    "\n",
    "## Make sure to check how many people and votes, relative to the total matrix, you are losing given min vote threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full participants * comments matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice about the matrix: comments are submitted over time, so participants who do not return will only have voted on the statements which were avialable when they arrived. \n",
    "\n",
    "Long horizontal lines: participants who do return show up as a horizontal line sticking out into otherwise blank areas\n",
    "\n",
    "Blank vertical lines: most likely statements which were moderated out of the conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "sns.heatmap(vals_all_in, center=0, cmap=\"RdYlBu\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_pca(dataframe, components):\n",
    "    pca_object = PCA(n_components=components) ## pca is apparently different, it wants \n",
    "    pca_object = pca_object.fit(dataframe.T) ## .T transposes the matrix (flips it)\n",
    "    coords = pca_object.components_.T ## isolate the coordinates and flip \n",
    "    explained_variance = pca_object.explained_variance_ratio_\n",
    "\n",
    "    return coords, explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(comment, coords):\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    colorMap = {-1:'#A50026', 1:'#313695', 0:'#FEFEC050'}\n",
    "    ax.scatter(\n",
    "        x=coords[:,0],\n",
    "        y=coords[:,1],\n",
    "        c=vals[str(comment)].apply(lambda x: colorMap[x]),\n",
    "        s=10\n",
    "    )\n",
    "    ax.set_title(\"\\n\".join(wrap(str(comment) + \"  \" + str(df_comments['comment-body'][comment]))), fontsize=14)\n",
    "    print('Colorcode is based on how voted not clustering!')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the space explained by how much people vote?\n",
    "\n",
    "In this chart, we take the PCA coordinates and color the participant locations by the number of total votes. Hopefully, it looks random. If it doesn't, we might imagine the following scenario:\n",
    "\n",
    "1. 1000 people vote, and there are very few controversial statements. They do not return.\n",
    "2. 1 person submits a statement which is incredibly controversial. \n",
    "3. 1000 more people vote, the space begins to take on structure, PCA is closely linked to vote count.\n",
    "\n",
    "We know this scenario - that voters don't see controversial comments - happens. Polis mitigates in two ways:\n",
    "* polis eliminates participants who don't vote at least 7 times from the analysis\n",
    "* polis shows several highly controversial comments (large egeinvalue) in the first 10 comments participants see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, embedding = polis_pca(vals_all_in, 2)\n",
    "\n",
    "plt.figure(figsize=(7, 5), dpi=80)\n",
    "plt.scatter(\n",
    "    x=coords[:,0], \n",
    "    y=coords[:,1], \n",
    "    c=metadata['n-votes'],\n",
    "    cmap=\"magma_r\",\n",
    "    s=5\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion groups\n",
    "\n",
    "To form opinion groups, we take the PCA coordinates and perform K-means clustering with K=100. \n",
    "These fine-graine cluster serve as the basis for a more coarse-grained clustering, also using K-means. \n",
    "<font color='red'>\n",
    "*In fact, we take the 100 centers (obtained from the first K-means clustering), and run additional K-means clustering for K ranging between 2 and 5.*\n",
    "</font>\n",
    "The K for which the silhoutte coefficient (a measure of withing-cluster similarity vs. between-cluster dissimilarity) is optimal is chosen for the opinion groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a dataframe, returns the found lables/clusters and the corresponding centers\n",
    "def polis_kmeans_(dataframe, n_clusters=2):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(dataframe)\n",
    "    \n",
    "    return kmeans.labels_, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_with_clusters(embedding_,labels_):\n",
    "    print(\"Plotting PCA embeddings with K-means, K=\"+str(np.max(labels_)+1))\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    ax.scatter(\n",
    "        x=embedding_[:,0],\n",
    "        y=embedding_[:,1],\n",
    "        c=labels_,\n",
    "        cmap=\"tab20\",\n",
    "        s=5\n",
    "    )\n",
    "    #ax.set_title(\"\", fontsize=14)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - get PCA clusters \n",
    "embedding, explained_variance = polis_pca(vals_all_in, 2)  \n",
    "print(\"Explained variance:\", explained_variance)\n",
    "\n",
    "# Step 2 - K-means with K=100\n",
    "clusters_100, centers = polis_kmeans_(embedding,n_clusters=100)\n",
    "plot_embedding_with_clusters(embedding, clusters_100)\n",
    "\n",
    "# Step 3 - find optimal K\n",
    "from sklearn.metrics import silhouette_score \n",
    "silhoutte_star = -np.inf\n",
    "for K in range(2,6):\n",
    "    clusters_K, _ = polis_kmeans_(centers,n_clusters=K)\n",
    "    silhouette_K = silhouette_score(centers, clusters_K)\n",
    "    if silhouette_K >= silhoutte_star:\n",
    "        K_star = K\n",
    "        silhoutte_star = silhouette_K\n",
    "        clusters_K_star = clusters_K\n",
    "print('Optimal clusters for K=',str(K_star))\n",
    "plot_embedding_with_clusters(centers,clusters_K_star)\n",
    " \n",
    "# Step 4 - assign each voter to \"optimal\" cluster\n",
    "clusters_star = np.zeros(len(clusters_100))\n",
    "for k in range(100):#\n",
    "    #find all indices with clusters k and assign them new star label\n",
    "    clusters_star[np.where(clusters_100==k)]  = clusters_K_star[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Statistics\n",
    "\n",
    "We analyze comments for how strongly they represent each opinion group.\n",
    "For that, the representative metric R_v(g,c) is calculated for all groups g, comments c, and possible votes v.\n",
    "This metric estimates how much more likely participants in group g are vote v on said comment c than those outside group g.\n",
    "\n",
    "*Definition of R_v(g,c):*\n",
    "Let N_v(g,c) be the number of participants in group g who cast vote v on comment c, and let N(g,c)   be the total number of votes for comment c within group g (i.e. <font color='red'> N_{+1}(g,c)+  N_{-1}(g,c) <font> )\n",
    "\n",
    "Defifne P_v(g,c)=(1+N_v(g,v))/(2+N(g,c)) which estimates the probability that a given person in group g votes v on comment c. Then\n",
    "\n",
    "R_v(g,c) = P_v(g,c)/ P_v(g_not,c)\n",
    "\n",
    "where g_not denotes the complement of g, thus all participants not in g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Calculate N_v(g,c), N(g,c), and P_v(g,c)\n",
    "N_groups, N_comments = clusters_K_star.max()+1, len(statements_all_in)\n",
    "N_v_g_c = np.zeros([3,N_groups,N_comments]) #create N matrix \n",
    "P_v_g_c = np.zeros([3,N_groups,N_comments])\n",
    "N_g_c = np.zeros([N_groups,N_comments])\n",
    "v_values = [-1,0,1]\n",
    "\n",
    "for g in range(N_groups): \n",
    "    idx_g = np.where(clusters_star == g)[0] #get indices of cluster g; caution_ idx != participant id\n",
    "    for c in range(N_comments):\n",
    "        comment = statements_all_in[c] #comment id\n",
    "        df_c = vals_all_in[str(comment)].iloc[idx_g] #data frame: [participants of group g,comment c], \n",
    "        for v in range(3):\n",
    "            v_value = v_values[v]\n",
    "            N_v_g_c[v,g,c] = (df_c == v_value).sum() #counts all v_value votes in data frame df_c\n",
    "        N_g_c[g,c] = N_v_g_c[0,g,c] + N_v_g_c[2,g,c] #total votes corresponds to votes with +1 or -1  \n",
    "        \n",
    "        for v in range(3):\n",
    "            P_v_g_c[v,g,c] = (1 + N_v_g_c[v,g,c]) / (2 + N_g_c[g,c])\n",
    "        \n",
    "#Step2: calculate R_v(g,c)                           \n",
    "R_v_g_c = np.zeros([3,N_groups,N_comments])\n",
    "for g in range(N_groups): \n",
    "    for c in range(N_comments):\n",
    "        for v in range(3):\n",
    "           R_v_g_c[v,g,c] = P_v_g_c[v,g,c] / np.delete(P_v_g_c[v,:,c],g,0).sum()  # np.delete neglects all entries with group g                                           \n",
    "                                                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Selection criterion\n",
    "\n",
    "Given R_v(g,c), how to decide weather comment c is representative for group g?\n",
    "\n",
    "Remember: R_v(g,c)=2 means that comment c is 2 times more likely to be voted v in group g compared to all the other groups. \n",
    "However, this does not tell us how significant this difference is (a very small likelihood multiplied by 2 is still a very small likelihood).\n",
    "\n",
    "<font color='red'> \n",
    "As a measure of significance, we calculate the Fisher exact test. This quantity can be regarded as a measure of correlation between two random variables. In fact, it tests how significantly the obtained sample (in this case votes v of comment c in group g) is different from the 0 hypothesis (in this case, that votes v are drawn from a hypergeometric distribution with parameters given by including all groups on comment c). \n",
    "<font>\n",
    "\n",
    "We weight this significance measure with R_v(g,c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "v_values = [-1,0,1]\n",
    "p_values = np.zeros([N_groups,N_comments,3])\n",
    "for g in range(N_groups): \n",
    "    idx_g = np.where(clusters_star == g)[0] #get indices of cluster g; caution_ idx != participant id\n",
    "    idx_g_not = np.where(clusters_star != g)[0] #get indices of rest\n",
    "    for c in range(N_comments):\n",
    "        comment = statements_all_in[c] #comment id\n",
    "        \n",
    "        for v in range(3):\n",
    "            v_value = v_values[v]\n",
    "            N_v = (vals_all_in[str(comment)] == v_value).sum()    #totol number of v votes in comment c\n",
    "            N_rest = (vals_all_in[str(comment)]).count() - N_v    #total number of votes =  number of participants\n",
    "            \n",
    "            df_c = vals_all_in[str(comment)].iloc[idx_g]  #get data frame of group g for comment c\n",
    "            N_v_in_g = (df_c == v_value).sum()\n",
    "            N_g = (df_c).count()   \n",
    "            \n",
    "            [M, n, N] = [N_rest+N_v, N_v, N_g]  #hypergeometric distribution parameters https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.hypergeom.html\n",
    "            x = range(N_v_in_g-1 ,N_g+1)\n",
    "            prb = hypergeom.pmf(x, M, n, N).sum() #calculates P(X>=N_v_in_g), i.e. p-value. \n",
    "            p_values[g,c,v] = prb * R_v_g_c[v,g,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets print the most significant comments for each group!\n",
    "for g in range(N_groups): \n",
    "    idx_ = np.argsort(p_values[g,:,0]) #take only the significant comments\n",
    "    print('----------------------------------')\n",
    "    print('5 significant comments for group ',g)\n",
    "    print('----------------------------------')\n",
    "    for i in range(5):\n",
    "        print(' ')\n",
    "        print(df_comments['comment-body'][idx_[i]])\n",
    "        print(' ')\n",
    "        \n",
    "        #How to embed comments into plot?\n",
    "        #idx_[i]\n",
    "        #participant_comment = np.zeros([1,vals_all_in.shape[0]])\n",
    "        #participant_comment[0,idx_[i]] = 1\n",
    "        #latent_comment = pca_object.transform(participant_comment)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets also include the 5 most significant comments into the PCA embeddings\n",
    "## for that, treat a comment as a artificial participant who only voted on the respective comment \n",
    "## and use the already calculated PCA loadings to project to the 2d plane\n",
    "\n",
    "plot_embedding_with_clusters(centers,clusters_K_star)\n",
    "\n",
    "pca_object = PCA(n_components=2) ## pca is apparently different, it wants \n",
    "pca_object = pca_object.fit(vals_all_in.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
