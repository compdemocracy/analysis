{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pol-is/notebooks/blob/master/020-PCA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "from textwrap import wrap\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numba\n",
    "\n",
    "import umap\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up plots\n",
    "plt.figure(figsize=(500, 500))\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "sns.set_theme(font_scale=.7)\n",
    "sns.set_color_codes()\n",
    "\n",
    "%matplotlib inline\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw data && clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/bowling-green.american-assembly/participants-votes.csv',index_col='participant')\n",
    "df_comments = pd.read_csv('../../data/bowling-green.american-assembly/comments.csv',index_col='comment-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.index = df_comments.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fields = ['group-id', 'n-comments', 'n-votes', \n",
    "                   'n-agree', 'n-disagree']\n",
    "val_fields = [c for c in df.columns.values if c not in metadata_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove statements (columns) which were moderated out\n",
    "statements_all_in = sorted(list(df_comments.loc[df_comments[\"moderated\"] > 0].index.array), key = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for a row, count the number of finite values\n",
    "def count_finite(row):\n",
    "    finite = np.isfinite(row[val_fields]) # boolean array of whether each entry is finite\n",
    "    return sum(finite) # count number of True values in `finite`\n",
    "\n",
    "## REMOVE PARTICIPANTS WITH LESS THAN N VOTES check for each row if the number of finite values >= cutoff\n",
    "def select_rows(df, threshold=60):\n",
    "    \n",
    "    number_of_votes = df.apply(count_finite, axis=1)\n",
    "    valid = number_of_votes >= threshold\n",
    "    \n",
    "    return df[valid]\n",
    "    \n",
    "df = select_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = df[metadata_fields]\n",
    "vals = df[val_fields]\n",
    "# If the participant didn't see the statement, it's a null value, here we fill in the nulls with zeros\n",
    "vals = vals.fillna(0)\n",
    "vals = vals.sort_values(\"participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_variance = [\n",
    "    \"20\",\"26\",\"90\"\n",
    "]\n",
    "\n",
    "vals_high_variance = vals[high_variance]\n",
    "\n",
    "statements_consensus = [\n",
    "    \"39\",\"200\",\"83\",\"82\",\"737\",\"64\",\"127\",\"126\",\"66\",\n",
    "]\n",
    "\n",
    "vals_consensus = vals[statements_consensus]\n",
    "\n",
    "consensus_disagree = [\n",
    "    \"353\",\"779\",\"720\",\"354\"\n",
    "]\n",
    "\n",
    "vals_consensus_disagree = vals[consensus_disagree]\n",
    "\n",
    "statements_opiods = [\n",
    "    \"9\",\n",
    "    \"19\",\n",
    "    \"11\",\n",
    "    \"10\",\n",
    "    \"675\",\n",
    "    \"753\",\n",
    "    \"742\",\n",
    "    \"336\",\n",
    "    \"329\",\n",
    "    \"683\",\n",
    "    \"686\",\n",
    "    \"894\",\n",
    "    \"885\",\n",
    "    \"846\",\n",
    "    \"688\",\n",
    "    \"679\",\n",
    "    \"678\",\n",
    "    \"676\",\n",
    "]\n",
    "vals_opiods = vals[statements_opiods]\n",
    "\n",
    "\n",
    "statements_homelessness = [\n",
    "    \"24\",\"25\",\"34\",\n",
    "#     \"45\",\n",
    "    \"55\",\n",
    "    \"103\",\"105\",\"106\",\"147\",\n",
    "    \"160\",\"232\",\"233\",\n",
    "    \"404\",\n",
    "#     \"535\", \n",
    "#     \"586\",\n",
    "#     \"782\",\n",
    "#     \"828\",\n",
    "]\n",
    "vals_homelessness = vals[statements_homelessness]\n",
    "\n",
    "                              \n",
    "\n",
    "vals_all_in = vals[statements_all_in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How sparse is the dataset? How much agree, how much disagree, how much pass? Zero is 'passed' or 'did not see the comment to vote on it'. 1 is agree, -1 is disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = vals.melt();\n",
    "all_votes = melted.count();\n",
    "by_type = melted[\"value\"].value_counts();\n",
    "total_possible_votes = all_votes[\"value\"];\n",
    "total_agrees = by_type[1.0];\n",
    "total_disagrees = by_type[-1.0];\n",
    "total_without_vote = by_type[0.0];\n",
    "\n",
    "print(\"Dimensions of matrix:\", df.shape)\n",
    "print(\"Dimensions of matrix:\", vals.shape)\n",
    "print(\"Total number of possible votes:\", total_possible_votes)\n",
    "print(\"Total number of agrees:\", total_agrees)\n",
    "print(\"Total number of disagrees:\", total_disagrees)\n",
    "print(\"Total without vote:\", total_without_vote)\n",
    "print(\"Percent sparse: \", total_without_vote / total_possible_votes,\"%\")\n",
    "\n",
    "## Make sure to check how many people and votes, relative to the total matrix, you are losing given min vote threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full participants * comments matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice about the matrix: comments are submitted over time, so participants who do not return will only have voted on the statements which were avialable when they arrived. \n",
    "\n",
    "Long horizontal lines: participants who do return show up as a horizontal line sticking out into otherwise blank areas\n",
    "\n",
    "Blank vertical lines: most likely statements which were moderated out of the conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "sns.heatmap(vals_all_in, center=0, cmap=\"RdBu\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def sparsity_aware_dist(a, b):\n",
    "    n_both_seen = len(a) - (np.isnan(a) | np.isnan(b)).sum()\n",
    "    return (n_both_seen - (a == b).sum() + 1) / (n_both_seen + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_pca(dataframe, components):\n",
    "    pca_object = PCA(n_components=components) ## pca is apparently different, it wants \n",
    "    pca_object = pca_object.fit(dataframe.T) ## .T transposes the matrix (flips it)\n",
    "    coords = pca_object.components_.T ## isolate the coordinates and flip \n",
    "    explained_variance = pca_object.explained_variance_ratio_\n",
    "\n",
    "    return coords, explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_umap(dataframe, neighbors):\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=neighbors,\n",
    "        metric=sparsity_aware_dist,\n",
    "        init='random',\n",
    "        min_dist=0.1,\n",
    "        spread=1.0,\n",
    "        local_connectivity=3.0,\n",
    "    )\n",
    "    embedding = reducer.fit_transform(dataframe.values)\n",
    "    # embedding.shape\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(comment, coords):\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    colorMap = {-1:'#A50026', 1:'#313695', 0:'#FEFEC050'}\n",
    "    ax.scatter(\n",
    "        x=coords[:,0],\n",
    "        y=coords[:,1],\n",
    "        c=vals[str(comment)].apply(lambda x: colorMap[x]),\n",
    "        s=10\n",
    "    )\n",
    "    ax.set_title(\"\\n\".join(wrap(str(comment) + \"  \" + str(df_comments['comment-body'][comment]))), fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thanks to https://github.com/ciortanmadalina/high_noise_clustering/blob/master/graph-partitioning-louvain.ipynb\n",
    "\n",
    "def polis_leiden(dataframe, neighbors):\n",
    "    A = kneighbors_graph(\n",
    "        dataframe.values, \n",
    "        neighbors, \n",
    "        mode=\"connectivity\", \n",
    "        metric=sparsity_aware_dist, \n",
    "        p=3, \n",
    "        metric_params=None, \n",
    "        include_self=True, \n",
    "        n_jobs=None\n",
    "    )\n",
    "\n",
    "    sources, targets = A.nonzero()\n",
    "    weights = A[sources, targets]\n",
    "    if isinstance(weights, np.matrix): # ravel data\n",
    "            weights = weights.A1\n",
    "\n",
    "    g = ig.Graph(directed=False)\n",
    "    g.add_vertices(A.shape[0])  # each observation is a node\n",
    "    edges = list(zip(sources, targets))\n",
    "    g.add_edges(edges)\n",
    "    g.es['weight'] = weights\n",
    "    weights = np.array(g.es[\"weight\"]).astype(np.float64)\n",
    "\n",
    "    part = leidenalg.find_partition(\n",
    "        g, \n",
    "        leidenalg.ModularityVertexPartition\n",
    "    );\n",
    "\n",
    "    leidenClusters = np.array(part.membership)\n",
    "    leidenClustersStr = [str(i) for i in leidenClusters] \n",
    "\n",
    "    #df[\"leiden\"] = leidenClustersStr\n",
    "    \n",
    "    return leidenClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_subconversation(dataframe, comments):\n",
    "    coords, explained_variance = polis_pca(dataframe, 2)\n",
    "    print(\"Explained variance:\", explained_variance)\n",
    "\n",
    "    embedding = polis_umap(dataframe, 10)\n",
    "\n",
    "    leidenClusters = polis_leiden(dataframe, 8)\n",
    "\n",
    "\n",
    "    # Show clusters given umap embedding \n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    ax.scatter(\n",
    "        x=embedding[:,0],\n",
    "        y=embedding[:,1],\n",
    "        c=leidenClusters,\n",
    "        cmap=\"tab20\",\n",
    "        s=5\n",
    "    )\n",
    "    ax.set_title(\"Leiden detected communities in UMAP space\", fontsize=14)\n",
    "\n",
    "\n",
    "    # Show clusters given pca embedding \n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    ax.scatter(\n",
    "        x=coords[:,0],\n",
    "        y=coords[:,1],\n",
    "        c=leidenClusters,\n",
    "        cmap=\"tab20\",\n",
    "        s=5\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Leiden detected communities in PCA space\", fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    # number of votes in pca space\n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "    plt.scatter(\n",
    "        x=coords[:,0], \n",
    "        y=coords[:,1], \n",
    "        c=metadata['n-votes'],\n",
    "        cmap=\"magma_r\",\n",
    "        s=5\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # when did the participant show up? index\n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "    plt.scatter(\n",
    "        x=coords[:,0], \n",
    "        y=coords[:,1], \n",
    "        c=metadata.index,\n",
    "        cmap=\"magma_r\",\n",
    "        s=5\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "    # PCA for COMMENTS\n",
    "    \n",
    "    coords, explained_variance = polis_pca(dataframe.T, 2)\n",
    "    \n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "    plt.scatter(\n",
    "        x=coords[:,0], \n",
    "        y=coords[:,1], \n",
    "#         c=,\n",
    "        cmap=\"magma_r\",\n",
    "        s=5\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "#     plt.colorbar()\n",
    "    \n",
    "#     # Show clustermap\n",
    "#     dataframe['leiden_cluster_assignments'] = leidenClusters\n",
    "#     clusters_by_comments_means = dataframe.groupby('leiden_cluster_assignments').agg('mean')\n",
    "\n",
    "#     #sns.heatmap(clusters_by_comments_means, cmap=\"RdYlBu\")\n",
    "#     sns.clustermap(clusters_by_comments_means, cmap=\"RdYlBu\", figsize=(15,15))\n",
    "\n",
    "    for x in comments:\n",
    "        c(x, coords)\n",
    "        c(x, embedding)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_heatmap(__dataframe):\n",
    "    leidenClusters = polis_leiden(__dataframe, 8)\n",
    "\n",
    "    # Show clustermap\n",
    "    __dataframe['leiden_cluster_assignments'] = leidenClusters\n",
    "    clusters_by_comments_means = __dataframe.groupby('leiden_cluster_assignments').agg('mean').T\n",
    "\n",
    "    index_to_label = df_comments['comment-body'].to_dict() # {index: label}\n",
    "\n",
    "    clustergrid = sns.clustermap(clusters_by_comments_means, cmap=\"RdBu\", figsize=(10,10), )\n",
    "\n",
    "    ax = clustergrid.ax_heatmap\n",
    "    new_labels = [index_to_label[str(idx._text)] for idx in ax.get_yticklabels()] # [ label0, label1, label2, ...]\n",
    "    ax.set_yticklabels(new_labels, rotation=0, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the space explained by how much people vote?\n",
    "\n",
    "In this chart, we take the PCA coordinates and color the participant locations by the number of total votes. Hopefully, it looks random. If it doesn't, we might imagine the following scenario:\n",
    "\n",
    "1. 1000 people vote, and there are very few controversial statements. They do not return.\n",
    "2. 1 person submits a statement which is incredibly controversial. \n",
    "3. 1000 more people vote, the space begins to take on structure, PCA is closely linked to vote count.\n",
    "\n",
    "We know this scenario - that voters don't see controversial comments - happens. Polis mitigates in two ways:\n",
    "* polis eliminates participants who don't vote at least 7 times from the analysis\n",
    "* polis shows several highly controversial comments (large egeinvalue) in the first 10 comments participants see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, embedding = polis_pca(vals_all_in, 2)\n",
    "\n",
    "plt.figure(figsize=(7, 5), dpi=80)\n",
    "plt.scatter(\n",
    "    x=coords[:,0], \n",
    "    y=coords[:,1], \n",
    "    c=metadata['n-votes'],\n",
    "    cmap=\"magma_r\",\n",
    "    s=5\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polis_subconversation(vals_all_in, high_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polis_subconversation(vals_all_in, statements_consensus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polis_heatmap(vals_opiods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polis_subconversation(vals_opiods, statements_opiods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homelessness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     leidenClusters = polis_leiden(__dataframe, 8)\n",
    "\n",
    "    # Show clustermap\n",
    "#     __dataframe['leiden_cluster_assignments'] = leidenClusters\n",
    "\n",
    "index_to_label = df_comments['comment-body'].to_dict() # {index: label}\n",
    "\n",
    "clustergrid = sns.clustermap(vals_homelessness, cmap=\"RdBu\", figsize=(10,10), )\n",
    "\n",
    "ax = clustergrid.ax_heatmap\n",
    "new_labels = [index_to_label[str(idx._text)] for idx in ax.get_xticklabels()] # [ label0, label1, label2, ...]\n",
    "ax.set_xticklabels(new_labels, rotation=90, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polis_heatmap(vals_homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  polis_subconversation(vals_homelessness, statements_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords, explained_variance = polis_pca(vals_all_in, 2)\n",
    "# print(\"Explained variance:\", explained_variance)\n",
    "\n",
    "# embedding = polis_umap(vals_all_in, 4)\n",
    "\n",
    "# leidenClusters = polis_leiden(vals_all_in, 8)\n",
    "\n",
    "# # Show clusters given umap embedding \n",
    "# fig, ax = plt.subplots(figsize=(7,5))\n",
    "# plt.sca(ax)\n",
    "# ax.scatter(\n",
    "#     x=embedding[:,0],\n",
    "#     y=embedding[:,1],\n",
    "#     c=leidenClusters,\n",
    "#     cmap=\"tab20\",\n",
    "#     s=5\n",
    "# )\n",
    "\n",
    "# ax.set_title(\"Leiden detected communities in UMAP space\", fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# for x in statements_all_in:\n",
    "#     if int(x) < 5:\n",
    "#         c(x, coords)\n",
    "#         c(x, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leidenClusters = polis_leiden(vals_opiods, 8)\n",
    "\n",
    "# # Show clustermap\n",
    "# vals_opiods['leiden_cluster_assignments'] = leidenClusters\n",
    "# clusters_by_comments_means = vals_opiods.groupby('leiden_cluster_assignments').agg('mean').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_label = df_comments['comment-body'].to_dict() # {index: label}\n",
    "\n",
    "# clustergrid = sns.clustermap(clusters_by_comments_means, cmap=\"RdYlBu\", figsize=(15,15), )\n",
    "\n",
    "# ax = clustergrid.ax_heatmap\n",
    "# new_labels = [index_to_label[str(idx._text)] for idx in ax.get_yticklabels()] # [ label0, label1, label2, ...]\n",
    "# ax.set_yticklabels(new_labels, rotation=0, fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
